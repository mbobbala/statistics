{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "some youtube links: (Hypothesis Testing) https://www.youtube.com/watch?v=_Qlxt0HmuOo\n",
    "https://www.youtube.com/watch?v=KTFm7El1NBs&list=PLnVYEpTNGNtVa489GMepY9mk36VPymhzi https://www.youtube.com/watch?v=EOlNb1XXC_M&list=PLnVYEpTNGNtXVA7cR_H85j5Lxw8JOoX1z\n",
    "\n",
    "**Khan Academy** is good source for understaning:\n",
    "https://www.youtube.com/watch?v=-FtlH4svqx4\n",
    "\n",
    "Following:\n",
    "https://github.com/rouseguy/intro2stats/blob/master/notebooks/6.%20Hypothesis%20Testing.ipynb\n",
    "\n",
    "Below is link for jupyter markdown options\n",
    "https://medium.com/analytics-vidhya/the-ultimate-markdown-guide-for-jupyter-notebook-d5e5abf728fd\n",
    "\n",
    "\n",
    "A guide to master Hypothesis Testing:\n",
    "https://www.analyticsvidhya.com/blog/author/sunil-ray/\n",
    "https://www.analyticsvidhya.com/blog/2015/09/hypothesis-testing-explained/\n",
    "I really liked this article. Very well explained and made my understanding of hypothesis testing very clear.\n",
    "\n",
    "Good Source for chi-square:\n",
    "https://www.analyticsvidhya.com/blog/2019/11/what-is-chi-square-test-how-it-works/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy import stats\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/manognabobbala/Documents/ML_DataScience/Statistics_mb\n",
      "['.DS_Store', 'hopothesis_testing_1.ipynb', 'intro2stats-master', '.ipynb_checkpoints', 'resampling.ipynb', 'data', 'coin_toss.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "print(os.listdir(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        State   HighQ  HighQN    MedQ  MedQN    LowQ  LowQN        date\n",
      "0     Alabama  339.06    1042  198.64    933  149.49    123  2014-01-01\n",
      "1      Alaska  288.75     252  260.60    297  388.58     26  2014-01-01\n",
      "2     Arizona  303.31    1941  209.35   1625  189.45    222  2014-01-01\n",
      "3    Arkansas  361.85     576  185.62    544  125.87    112  2014-01-01\n",
      "4  California  248.78   12096  193.56  12812  192.92    778  2014-01-01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State      object\n",
       "HighQ     float64\n",
       "HighQN      int64\n",
       "MedQ      float64\n",
       "MedQN       int64\n",
       "LowQ      float64\n",
       "LowQN       int64\n",
       "date       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weed_pd = pd.read_csv(\"/Users/manognabobbala/Documents/ML_DataScience/Statistics_mb/data/Weed_Price.csv\")\n",
    "#weed_pd[\"month\"] = weed_pd.date.apply(lambda x: x.month)\n",
    "#weed_pd[\"year\"] = weed_pd.date.apply(lambda x: x.year)\n",
    "print(weed_pd.head())\n",
    "weed_pd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        State   HighQ  HighQN    MedQ  MedQN    LowQ  LowQN        date  \\\n",
      "0     Alabama  339.06    1042  198.64    933  149.49    123  2014-01-01   \n",
      "1      Alaska  288.75     252  260.60    297  388.58     26  2014-01-01   \n",
      "2     Arizona  303.31    1941  209.35   1625  189.45    222  2014-01-01   \n",
      "3    Arkansas  361.85     576  185.62    544  125.87    112  2014-01-01   \n",
      "4  California  248.78   12096  193.56  12812  192.92    778  2014-01-01   \n",
      "\n",
      "    date_col  month  year  \n",
      "0 2014-01-01      1  2014  \n",
      "1 2014-01-01      1  2014  \n",
      "2 2014-01-01      1  2014  \n",
      "3 2014-01-01      1  2014  \n",
      "4 2014-01-01      1  2014  \n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "weed_pd['date_col'] =  pd.to_datetime(weed_pd['date'])\n",
    "weed_pd.dtypes\n",
    "weed_pd[\"month\"] = weed_pd.date_col.apply(lambda x: x.month)\n",
    "weed_pd[\"year\"] = weed_pd.date_col.apply(lambda x: x.year)\n",
    "print(weed_pd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "weed_cali_2014 = weed_pd[ (weed_pd['year']==2014) & (weed_pd['State'] == 'California') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 245.8942307692309\n",
      "Standard Deviation: 1.289907939371412\n"
     ]
    }
   ],
   "source": [
    "#Mean and standard deviation of high quality weed's price\n",
    "print(\"Mean:\", weed_cali_2014.HighQ.mean())\n",
    "print(\"Standard Deviation:\", weed_cali_2014.HighQ.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245.761718492726, 246.02674304573577)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confidence interval on the mean\n",
    "stats.norm.interval(0.95, loc=weed_cali_2014.HighQ.mean(), scale = weed_cali_2014.HighQ.std()/np.sqrt(len(weed_cali_2014)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Are high-quality weed prices in Jan 2014 significantly higher than in Jan 2015?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-2014 Jan: 248.4454838709677\n",
      "Mean-2015 Jan: 243.60225806451612\n"
     ]
    }
   ],
   "source": [
    "#Get the data\n",
    "weed_ca_jan2014 = np.array(weed_pd[(weed_pd.State==\"California\") & (weed_pd.year==2014) & (weed_pd.month==1)].HighQ)\n",
    "weed_ca_jan2015 = np.array(weed_pd[(weed_pd.State==\"California\") & (weed_pd.year==2015) & (weed_pd.month==1)].HighQ)\n",
    "print(\"Mean-2014 Jan:\", weed_ca_jan2014.mean())\n",
    "print(\"Mean-2015 Jan:\", weed_ca_jan2015.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect size: 4.843225806451585\n"
     ]
    }
   ],
   "source": [
    "print(\"Effect size:\", weed_ca_jan2014.mean() - weed_ca_jan2015.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=98.01132523815805, pvalue=6.297971818508403e-68)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(weed_ca_jan2014, weed_ca_jan2015, equal_var=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null Hypothesis: Mean prices aren't significantly different\n",
    "\n",
    "Perform t-test and determine the p-value.\n",
    "\n",
    "p-value is the probability that the effective size was by chance. And here, p-value is almost 0.\n",
    "\n",
    "Conclusion: Reject the null hypotheses. The price difference is significant. \n",
    "\n",
    "\n",
    "Assumption of t-testÂ¶\n",
    "One assumption is that the data used came from a normal distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next phase review other hypothesis tests like ks-test, chi-square etc\n",
    "## Review z-test and t-test in more detail later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-Square tests\n",
    "\n",
    "Chi-Square tests are used for categorical data\n",
    "\n",
    "The following two tests make use of chi-square statistic\n",
    "1. chi-square test for goodness of fit\n",
    "2. chi-square test for independence\n",
    "\n",
    "Chi-square test is a non-parametric test. They do not require assumptions about population parameters and they do not test hypotheses about population parameters.\n",
    "\n",
    "\n",
    "<h2> Chi-Square test for goodness fit </h2>\n",
    "$$ \\chi^2 = \\sum (O - E)^2/E $$\n",
    "\n",
    "* O is observed frequency\n",
    "* E is expected frequency\n",
    "* $ \\chi $ is the chi-square statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. Let's assume the proportion of people who bought High, Medium and Low quality weed in Jan-2014 as the expected proportion. Find if proportion of people who bought weed in Jan 2015 conformed to the norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: [2918004 2644757  263958] \n",
      " Observed: [4057716 4035049  358088]\n",
      "Expected: [0.5007971  0.45390159 0.04530131] \n",
      " Observed: [0.48015461 0.47747239 0.042373  ]\n"
     ]
    }
   ],
   "source": [
    "weed_jan2014 = weed_pd[(weed_pd.year==2014) & (weed_pd.month==1)][[\"HighQN\", \"MedQN\", \"LowQN\"]]\n",
    "weed_jan2015 = weed_pd[(weed_pd.year==2015) & (weed_pd.month==1)][[\"HighQN\", \"MedQN\", \"LowQN\"]]\n",
    "\n",
    "Expected = np.array(weed_jan2014.apply(sum, axis=0))\n",
    "Observed = np.array(weed_jan2015.apply(sum, axis=0))\n",
    "\n",
    "print(\"Expected:\", Expected, \"\\n\" , \"Observed:\", Observed)\n",
    "print(\"Expected:\", Expected/np.sum(Expected.astype(float)), \"\\n\" , \"Observed:\", Observed/np.sum(Observed.astype(float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=1209562.2775169075, pvalue=0.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chisquare(Observed, Expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference : We reject null hypothesis. The proportions in Jan 2015 is different than what was expected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
